{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from My_Transformers.ipynb\n",
      "importing Jupyter notebook from Word2Vec_Transformer.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-11 22:23:46,531 INFO adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-11 22:23:46,532 INFO built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random  \n",
    "from random import sample \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.decomposition import PCA, NMF, KernelPCA, LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "from My_Transformers import *\n",
    "from Word2Vec_Transformer import WVEmbeddingTransformer, Text_cleaner_transformer, EMB_VOCAB_SET, WV_EMBEDDINGS\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleSave (obj, file):\n",
    "    \n",
    "    dirs = os.path.dirname (file) \n",
    "    if dirs:\n",
    "        os.makedirs (dirs, exist_ok=True)\n",
    "    with open (file, 'wb') as f:\n",
    "        pickle.dump (obj, f)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle (file):\n",
    "    return pickle.load (open (file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess (rawfile, newFileName):\n",
    "    \n",
    "    df = pd.read_csv (rawfile)\n",
    "    Xstr = df['text']\n",
    "    text_cleaner = Text_cleaner_transformer (isCorrection=True, embedding=WV_EMBEDDINGS)\n",
    "    Xstr = text_cleaner.transform (Xstr)\n",
    "    df['text'] = Xstr\n",
    "    df.to_csv (newFileName)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_file = \"Data/train.csv\"\n",
    "preprocessed_train_file = \"Data/preprocessed_train.csv\"\n",
    "preProcess (train_file, preprocessed_train_file)\n",
    "df = pd.read_csv (preprocessed_train_file)\n",
    "df = df[0:50]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xstr = df[\"text\"]\n",
    "y = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = FeatureUnion ([\n",
    "    \n",
    "    ('wv_embed', WVEmbeddingTransformer ('D:/Work/PythonPj/Jupyter/Word2Vec/GoogleNews-vectors-negative300.bin', vocabSet=EMB_VOCAB_SET, isCorrection=True)),\n",
    "    ('tfidf_latent_feat_select', Pipeline ([\n",
    "        \n",
    "        ('text_clean',       Text_cleaner_transformer ()),\n",
    "        ('tfidf_vectorizer', TfidfVectorizer (ngram_range=(1,2), max_df=0.9, min_df=5, token_pattern='(\\S+)')),\n",
    "        ('to_dense',         DenseTransformer ()),\n",
    "        ('tfidf_latent',     FeatureUnion ([\n",
    "            \n",
    "            ('latent', Pipeline ([\n",
    "                \n",
    "                ('feature_union',   FeatureUnion ([\n",
    "                    (\"pca_nmf_select\", PCA_NMF_FeatureTransformer ()),\n",
    "                    ('lda',            LDA_FeatureTransformer ()),\n",
    "                    ('kpca',           KPCA_FeatureTransformer (kernel=['rbf'])),\n",
    "                    ('ica',            ICA_FeatureTransformer ()),\n",
    "                ])),\n",
    "                ('k_best_feat_select_chi2', SelectKBest_feature_selector ()), # should not be used with -ve vals\n",
    "            ])),\n",
    "            ('tfidf', Pipeline ([\n",
    "                \n",
    "                ('sparse_svm_feat_select',  SparseSVM_feature_selector ()),\n",
    "            ]))\n",
    "        ])),\n",
    "        ('rf_feat_select',  CLF_importance_feature_selector ()),\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_transformer.fit_transform (Xstr, y)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleSave (feature_transformer, 'feature_transformer.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-11 22:24:43,451 INFO loading projection weights from D:/Work/PythonPj/Jupyter/Word2Vec/GoogleNews-vectors-negative300.bin\n",
      "2020-09-11 22:25:12,503 INFO loaded (3000000, 300) matrix from D:/Work/PythonPj/Jupyter/Word2Vec/GoogleNews-vectors-negative300.bin\n"
     ]
    }
   ],
   "source": [
    "# init the WVEmbeddingTransformer only once\n",
    "# EmbeddingTransformer = WVEmbeddingTransformer ('D:/Work/PythonPj/Jupyter/Word2Vec/GoogleNews-vectors-negative300.bin', vocabSet=EMB_VOCAB_SET, isCorrection=True, isinit=False)\n",
    "# Xemb = wvEmbeddingTransformer.fit_transform (Xstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_transformer = unpickle ('feature_transformer.bin')\n",
    "X = feature_transformer.transform (Xstr) \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleSave (X, 'X.bin')\n",
    "X = unpickle ('X.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try these classifiers: best = logisticReg cv=73.4%\n",
    "params_logit = { 'name' : 'Logit', 'params' : {'penalty' : 'l2'}, 'param_grid' : {'C' : [0.05, 0.1, 0.5, 1, 10]} }\n",
    "params_rf    = { 'name' : 'RF',    'params' : {'max_features' : None, 'class_weight':'balanced'}, \\\n",
    "                                                                  'param_grid' : {'warm_start' : [True, False]} } \n",
    "params_lsvc  = { 'name' : 'LSvc',  'params' : {'penalty' : 'l2', 'class_weight':'balanced'}, 'param_grid' : {'C' : [0.1, 1, 10]} }\n",
    "params_xgb   = { 'name' : 'Xgb',   'params' : {'n_estimators' : 50}, 'param_grid':{'max_depth': [3, 5], 'learning_rate':[1.5, 3]} }\n",
    "\n",
    "params = [params_logit, params_lsvc, params_xgb]\n",
    "bclfs  = []\n",
    "for param in params:\n",
    "    \n",
    "    bclf = Best_clf_cv_transformer (param)\n",
    "    bclf.fit (X, y) \n",
    "    bclfs.append ((bclf, bclf.get_cv_score()))\n",
    "# Choose the bclf with the best cv_score:\n",
    "bclf = max (bclfs, key = lambda i : i[1])[0]\n",
    "# pickleSave (bclf, 'bclf.bin')\n",
    "bclf = unpickle ('bclf.bin')\n",
    "bclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum (pd.isnull (df['keyword']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"Data/test.csv\"\n",
    "preprocessed_test_file = \"Data/preprocessed_test.csv\"\n",
    "preProcess (test_file, preprocessed_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3263, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv (preprocessed_test_file)\n",
    "Xstr = df[\"text\"]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_transformer.transform (Xstr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = bclf.predict (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleSave (predictions, 'predictions.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitDF = df[['id', 'target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       0\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       0\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submitDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitDF.to_csv ('submission_v1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
