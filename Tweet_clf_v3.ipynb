{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from My_Transformers.ipynb\n",
      "importing Jupyter notebook from Word2Vec_Transformer.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-23 07:29:40,348 INFO adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-09-23 07:29:40,350 INFO built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "import import_ipynb\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import random  \n",
    "from random import sample \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import scipy\n",
    "from tempfile import mkdtemp\n",
    "from shutil import rmtree\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "# from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from mlxtend.classifier import StackingClassifier, StackingCVClassifier\n",
    "from sklearn.decomposition import PCA, NMF, KernelPCA, LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier, Pool, cv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "import My_Transformers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Global var\n",
    "TRAIN_ROW_COUNT = 7964\n",
    "from My_Transformers import *\n",
    "from Word2Vec_Transformer import Text_cleaner_transformer\n",
    "import warnings\n",
    "warnings.filterwarnings (\"ignore\")\n",
    "\n",
    "# Global vars\n",
    "VERSION = 6.5\n",
    "trainDF = None\n",
    "testDF  = None\n",
    "CACHEDIR = mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleSave (obj, file):\n",
    "\n",
    "    if VERSION != '':\n",
    "\n",
    "        file, ext = os.path.splitext (file)\n",
    "        file += \"_v\" + str (VERSION) + ext\n",
    "    dirs = os.path.dirname (file) \n",
    "    if dirs:\n",
    "        os.makedirs (dirs, exist_ok=True)\n",
    "    with open (file, 'wb') as f:\n",
    "        pickle.dump (obj, f)\n",
    "    return\n",
    "\n",
    "def unpickle (file):\n",
    "\n",
    "    if VERSION != '':\n",
    "\n",
    "        file, ext = os.path.splitext(file)\n",
    "        file += \"_v\" + str(VERSION) + ext\n",
    "    return pickle.load (open (file, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discrete2OneHot_FeatureTransformer (BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.LB_1 = None\n",
    "        self.LB_2 = None\n",
    "        return\n",
    "\n",
    "    def fit (self, X, y=None, **fit_params):\n",
    "        print ('Discrete2OneHot_FeatureTransformer: fit(): X.shape =', X.shape)\n",
    "        self.LB_1 = LabelBinarizer ()\n",
    "        self.LB_1.fit (list (X['keyword']))\n",
    "        self.LB_2 = LabelBinarizer ()\n",
    "        self.LB_2.fit (list (pd.isnull (X['location'])))\n",
    "        return self\n",
    "\n",
    "    def transform (self, X, y=None, **fit_params):\n",
    "        \n",
    "        A = self.LB_1.transform (list (X['keyword']))\n",
    "        B = self.LB_2.transform (list (pd.isnull (X['location']))).reshape (-1, 1)\n",
    "        X = np.hstack ((A, B))\n",
    "        print ('Discrete2OneHot_FeatureTransformer: transform(): X.shape =', X.shape)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FV Trainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "\n",
    "pca_nmf_ft = ColumnTransformer ([ ('pca_nmf', Pipeline ([\n",
    "        \n",
    "        ('tfidf_vectorizer',        TfidfVectorizer (analyzer='char', ngram_range=(3, 7), max_df=0.90, min_df=5, token_pattern='(\\S+)')),\n",
    "        ('sparse_svm_feat_select1', SparseSVM_feature_selector ()),\n",
    "        ('interactions',            PolynomialFeatures (2, interaction_only=True, include_bias=False)),\n",
    "        ('sparse_svm_feat_select2', SparseSVM_feature_selector ()),\n",
    "        ('standardization',         StandardScaler (with_mean=False)),\n",
    "        ('pca_nmf',                 PCA_NMF_TrainTest_FeatureTransformer (isSparseOut=True))\n",
    "], memory=CACHEDIR), 'text')])\n",
    "\n",
    "\n",
    "tfidf_ft = ColumnTransformer ([ ('tfidf', Pipeline ([\n",
    "\n",
    "        ('tfidf_vectorizer',        TfidfVectorizer (analyzer='char', ngram_range=(3, 7), max_df=0.90, min_df=5, token_pattern='(\\S+)')),\n",
    "        ('sparse_svm_feat_select1', SparseSVM_feature_selector ()),\n",
    "        ('interactions',            PolynomialFeatures (2, interaction_only=True, include_bias=False)),\n",
    "        ('sparse_svm_feat_select2', SparseSVM_feature_selector ()),\n",
    "        ('standardization',         StandardScaler (with_mean=False))\n",
    "], memory=CACHEDIR), 'text')])\n",
    "\n",
    "\n",
    "pca_category_ft = ColumnTransformer ([\n",
    "        ('keyword_category', Discrete2OneHot_FeatureTransformer (), ['keyword', 'location']),\n",
    "        ('tfidf_pca',        Pipeline ([\n",
    "\n",
    "            ('tfidf_vectorizer',        TfidfVectorizer (analyzer='char', ngram_range=(3, 7), max_df=0.90, min_df=5, token_pattern='(\\S+)')),\n",
    "            ('sparse_svm_feat_select1', SparseSVM_feature_selector ()),\n",
    "            ('interactions',            PolynomialFeatures (2, interaction_only=True, include_bias=False)),\n",
    "            ('sparse_svm_feat_select2', SparseSVM_feature_selector ()),\n",
    "            ('standardization',         StandardScaler (with_mean=False)),\n",
    "            ('pca',                     PCA_NMF_TrainTest_FeatureTransformer (isNMF=False, isSparseOut=False))\n",
    "        ], memory=CACHEDIR), 'text')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init ():\n",
    "    \n",
    "    global pca_nmf_ft, tfidf_ft, pca_category_ft, trainDF\n",
    "    train_file = \"Data/all.csv\"\n",
    "    trainDF = pd.read_csv (train_file)\n",
    "    # df = df[0:20]\n",
    "    trainDF['text'] = trainDF.text.astype (str)\n",
    "    trainDF['keyword'] = trainDF.keyword.astype (str)\n",
    "    trainDF['location'] = trainDF.location.astype (str)\n",
    "    \n",
    "    # pca_nmf_ft.fit (trainDF, trainDF['target'])\n",
    "    # tfidf_ft.fit (trainDF, trainDF['target'])\n",
    "    # pca_category_ft.fit (trainDF, trainDF['target'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L-0 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "\n",
    "lsvc_1 = Pipeline ([\n",
    "    ('pca_nmf_ft', pca_nmf_ft),\n",
    "    ('clf',        Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.005, 0.01, 0.05, 0.1, 1, 10]} }) )\n",
    "], memory=CACHEDIR)\n",
    "lsvc_1.name = 'lsvc_1'\n",
    "\n",
    "lsvc_2 = Pipeline ([\n",
    "    ('tfidf_ft',   tfidf_ft),\n",
    "    ('clf',        Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.005, 0.01, 0.05, 0.1, 1, 10]} }) )\n",
    "], memory=CACHEDIR)\n",
    "lsvc_2.name = 'lsvc_2'\n",
    "\n",
    "lsvc_3 = Pipeline ([\n",
    "    ('pca_category_ft', pca_category_ft),\n",
    "    ('clf',        Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.005, 0.01, 0.05, 0.1, 1, 10]} }) )\n",
    "], memory=CACHEDIR)\n",
    "lsvc_3.name = 'lsvc_3'\n",
    "\n",
    "catb_1 = Pipeline ([\n",
    "    ('pca_nmf_ft', pca_nmf_ft),\n",
    "    ('clf',        Best_clf_cv_transformer ({ 'name': 'Catb',  'isCV': False}))\n",
    "], memory=CACHEDIR)\n",
    "catb_1.name = 'catb_1'\n",
    "\n",
    "catb_2 = Pipeline ([\n",
    "    ('tfidf_ft',   tfidf_ft),\n",
    "    ('clf',        Best_clf_cv_transformer ({ 'name': 'Catb',  'isCV': False}))\n",
    "], memory=CACHEDIR)\n",
    "catb_2.name = 'catb_2'\n",
    "\n",
    "catb_3 = Pipeline ([\n",
    "    ('pca_category_ft', pca_category_ft),\n",
    "    ('clf',             Best_clf_cv_transformer ({ 'name': 'Catb',  'isCV': False}))\n",
    "], memory=CACHEDIR)\n",
    "catb_3.name = 'catb_3'\n",
    "\n",
    "fcnn_1 = Pipeline ([\n",
    "    ('pca_category_ft', pca_category_ft),\n",
    "    ('clf',             Best_clf_cv_transformer ({ 'name': 'FCNN'}))\n",
    "], memory=CACHEDIR)\n",
    "fcnn_1.name = 'fcnn_1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global vars\n",
    "# Level 1\n",
    "\n",
    "sclf_1_1 = StackingClassifier (classifiers=[lsvc_1, lsvc_2, lsvc_3, catb_1, catb_2, catb_3, fcnn_1], \n",
    "                               meta_classifier=Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.005, 0.01, 0.05, 0.1, 1, 10]} }) )\n",
    "sclf_1_1.name = 'sclf_1_1'\n",
    "\n",
    "sclf_1_2 = StackingClassifier (classifiers=[lsvc_1, lsvc_2, lsvc_3, catb_1, catb_2, catb_3, fcnn_1],\n",
    "                               meta_classifier=Best_clf_cv_transformer ({ 'name': 'RF',    'params': {'class_weight': 'balanced', 'n_estimators': 3, 'max_features': None} }))\n",
    "sclf_1_2.name = 'sclf_1_2'\n",
    "\n",
    "sclf_1_3 = StackingClassifier (classifiers=[lsvc_1, lsvc_2, lsvc_3, catb_1, catb_2, catb_3, fcnn_1],\n",
    "                               meta_classifier=Best_clf_cv_transformer ({ 'name': 'Catb',  'isCV': False }))\n",
    "sclf_1_3.name = 'sclf_1_3'\n",
    "\n",
    "# Level 2\n",
    "\n",
    "sclf_2_1 = StackingClassifier (classifiers=[sclf_1_1, sclf_1_2, sclf_1_3],\n",
    "                                 meta_classifier=Best_clf_cv_transformer ({ 'name': 'LSvc',  'params': {'penalty': 'l2', 'class_weight': 'balanced'}, 'param_grid': {'C' : [0.005, 0.01, 0.05, 0.1, 1, 10]} }) )\n",
    "sclf_2_1.name = 'sclf_2_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train (clf):\n",
    "    \n",
    "    clf.fit (trainDF, trainDF['target'])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict (clf, iterCount=0):\n",
    "    \n",
    "    test_file = \"Data/test.csv\"\n",
    "    testDF = pd.read_csv (test_file)\n",
    "    # testDF = testDF[0:10]\n",
    "    testDF['text'] = testDF.text.astype (str)\n",
    "    testDF['keyword'] = testDF.keyword.astype (str)\n",
    "    testDF['location'] = testDF.location.astype (str)\n",
    "    \n",
    "    predictions = clf.predict (testDF)\n",
    "    testDF['target'] = predictions\n",
    "    testDF['target'] = testDF.target.astype (int)\n",
    "    submitDF = testDF[['id', 'target']]\n",
    "    submitDF.to_csv ('submission_v'+str (VERSION) + clf.name + '.' + str (iterCount+1) + '.csv', index=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init ()\n",
    "# train (sclf_2_1)\n",
    "# predict (sclf_2_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main (clf, threshold=0.9, maxIterCount=10, thresh_depreciation=0.01):\n",
    "\n",
    "    global trainDF, sclf_2_1\n",
    "    # init ()\n",
    "    newTrainAddCount = 1\n",
    "    iterCount = 0\n",
    "    while newTrainAddCount > 0:\n",
    "\n",
    "        threshold = threshold - iterCount * thresh_depreciation\n",
    "        if iterCount >= maxIterCount:\n",
    "            break\n",
    "        train (clf)\n",
    "        predict (clf, iterCount)\n",
    "        Pr = sclf_2_1.predict_proba (trainDF)\n",
    "        newTrainAddCount = 0\n",
    "        for idx, row in trainDF.iterrows ():\n",
    "            if not pd.isnull (row['target']):\n",
    "\n",
    "                continue\n",
    "            print ('considering idx =', idx)\n",
    "            pr = Pr[idx]\n",
    "            p  = 0\n",
    "            if pr[0] > 0.5:\n",
    "                pr = pr[0]\n",
    "                p  = 0\n",
    "            else:\n",
    "                pr = pr[1]\n",
    "                p  = 1\n",
    "            if pr >= threshold:\n",
    "                # add in the training set\n",
    "                trainDF.at[idx, 'target'] = p\n",
    "                newTrainAddCount += 1\n",
    "        # arrange df such that 1st rows with y=0/1 then rows with y=NaN\n",
    "        arrangedDF1 = trainDF[pd.isnull (trainDF['target']) == False]\n",
    "        arrangedDF2 = trainDF[pd.isnull (trainDF['target'])]\n",
    "        trainDF = pd.concat ([arrangedDF1, arrangedDF2], axis=0)\n",
    "        iterCount += 1\n",
    "    trainDF.to_csv ('Data/all_'+str (VERSION) + clf.name + '.' + str (iterCount+1)+'.csv', index=False)\n",
    "    train (clf)\n",
    "    predict (clf, iterCount)\n",
    "\n",
    "    # CV for the bclfs on the original train rows\n",
    "    print ('------------------- CV for the sclf_2_1 on the original train rows -------------------')\n",
    "    trainDF = trainDF[:TRAIN_ROW_COUNT]\n",
    "    cv_results = []\n",
    "    cv_result = cross_validate (sclf_2_1, trainDF, cv=5)\n",
    "    cv_score = np.mean (cv_result['test_score'])\n",
    "    print ()\n",
    "    print (clf.name, cv_score)\n",
    "    print (cv_result)\n",
    "    rmtree (CACHEDIR)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "main (sclf_2_1, maxIterCount=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean file\n",
    "import re\n",
    "text_cleaner_transformer = Text_cleaner_transformer ()\n",
    "files = [\"Data/all.csv\", \"Data/train.csv\", \"Data/test.csv\"]\n",
    "for file in files:\n",
    "    df = pd.read_csv (file)\n",
    "    df['text'] = text_cleaner_transformer.transform (df['text'])\n",
    "    df.to_csv (file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Findings\n",
    "\n",
    "LinearSVC with L1-based feature selection for X.shape = (7964, 83758)\n",
    "\n",
    "--------------------- Best parameter (CV score=0.693):\n",
    "\n",
    "{'feature_selection__estimator__tol': 0.001}\n",
    "\n",
    "New #features =  1393\n",
    "\n",
    "LinearSVC with L1-based feature selection for X.shape = (7964, 970921)\n",
    "\n",
    "--------------------- Best parameter (CV score=0.765):\n",
    "\n",
    "{'feature_selection__estimator__tol': 0.0001}\n",
    "\n",
    "New #features =  1374\n",
    "\n",
    "Find optimal PCA dims and the same no. of NMF features for X.shape = (11227, 1374)\n",
    "\n",
    "--------------------- Best:  parameters = (0.9, 0.1) , CV = 0.8258456437870457\n",
    "\n",
    "PCA dimensionality, explainedVarRatio =  784 0.9\n",
    "\n",
    "training LSvc for X.shape = (7964, 1568)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.829):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1374)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.818):\n",
    "\n",
    "{'C': 0.005}\n",
    "Done Fitting LSvc\n",
    "Discrete2OneHot_FeatureTransformer: fit(): X.shape = (11227, 2)\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Find optimal PCA dims for X.shape = (11227, 1374)\n",
    "\n",
    "--------------------- Best:  parameters = (0.9, 0.1) , CV = 0.8258456437870457\n",
    "\n",
    "PCA dimensionality, explainedVarRatio =  784 0.9\n",
    "training LSvc for X.shape = (7964, 1007)\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.826):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training Catb for X.shape = (7964, 1568)\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1374)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1007)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "training LSvc for X.shape = (7964, 6)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.973):\n",
    "\n",
    "{'C': 1}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1568)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.829):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1374)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.818):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1007)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.826):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training Catb for X.shape = (7964, 1568)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1374)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1007)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "training RF for X.shape = (7964, 6)\n",
    "\n",
    "RF : Best_clf_cv_transformer: starting CV = 5\n",
    "\n",
    "RF : cv_score:   0.973\n",
    "\n",
    "Done Fitting RF\n",
    "\n",
    "training LSvc for X.shape = (7964, 1568)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.829):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1374)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.818):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training LSvc for X.shape = (7964, 1007)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.826):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "training Catb for X.shape = (7964, 1568)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1374)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "training Catb for X.shape = (7964, 1007)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "training Catb for X.shape = (7964, 6)\n",
    "\n",
    "Done Fitting Catb\n",
    "\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "Discrete2OneHot_FeatureTransformer: transform(): X.shape = (11227, 223)\n",
    "\n",
    "training LSvc for X.shape = (7964, 3)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.974):\n",
    "\n",
    "{'C': 0.005}\n",
    "\n",
    "Done Fitting LSvc\n",
    "\n",
    "In the next iteration the final output CV score improved as:\n",
    "\n",
    "training LSvc for X.shape = (11471, 3) (11471,)\n",
    "\n",
    "LSvc : Best_clf_cv_transformer: Best parameter (CV score=0.979):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# without any cleaning, this scored 80 % in the kaggle test !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
